"""Query planner for intelligent retrieval strategy selection."""

import json
import logging
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional

from openai import OpenAI

from config import get_settings

logger = logging.getLogger(__name__)


class SearchIntent(str, Enum):
    """Classification of user query intent."""

    FIND_SPECIFIC_ITEM = "find_specific_item"  # "What is issue #123?"
    SEARCH_BY_CRITERIA = "search_by_criteria"  # "Issues labeled bug from last week"
    CODE_EXPLORATION = "code_exploration"  # "How does authentication work?"
    COMPARE_ITEMS = "compare_items"  # "Difference between MR 5 and 6"
    SUMMARIZE = "summarize"  # "Overview of recent activity"
    TROUBLESHOOT = "troubleshoot"  # "Why is feature X not working?"
    FOLLOW_UP = "follow_up"  # References previous answer
    GENERAL_QUESTION = "general_question"  # General questions about the project


class SearchStrategy(str, Enum):
    """Strategy for executing the search."""

    API_FIRST = "api_first"  # Fetch from API, then augment with vector
    VECTOR_FIRST = "vector_first"  # Semantic search, then API if needed
    PARALLEL = "parallel"  # Run both simultaneously and merge
    API_ONLY = "api_only"  # Only use GitLab API (specific items)
    VECTOR_ONLY = "vector_only"  # Only semantic search
    CODE_DEEP = "code_deep"  # Engage CodeAnalysisAgent


@dataclass
class SubQuery:
    """A single sub-query to execute."""

    query_type: str  # "vector", "api", "code_analysis"
    query: str  # The query text or action
    action: Optional[str] = None  # For API: "get_issue", "get_mr", "search_issues"
    params: Dict[str, Any] = field(default_factory=dict)  # Additional parameters
    content_types: Optional[List[str]] = None  # For vector search filtering
    priority: int = 1  # Lower = higher priority


@dataclass
class SearchPlan:
    """Complete search plan generated by QueryPlanner."""

    original_query: str
    intent: SearchIntent
    strategy: SearchStrategy
    reasoning: str
    sub_queries: List[SubQuery]
    content_priority: List[str]  # Ordered list of content types to prioritize
    requires_code_analysis: bool
    resolved_references: Dict[str, Any] = field(default_factory=dict)  # Resolved "it", "that issue" etc.
    confidence: float = 1.0  # How confident the planner is in this plan


class QueryPlanner:
    """AI-powered query planner for intelligent retrieval."""

    PLANNING_PROMPT = """You are a query planning assistant for a GitLab search system. Analyze the user's query and conversation history to create an optimal search plan.

## Available Data Sources
1. **Vector Database (Qdrant)**: Contains indexed issues, merge requests, code snippets, and comments. Best for semantic/conceptual searches.
2. **GitLab API**: Provides fresh, real-time data. Best for specific items (by IID), label searches, state filters, and recent updates.
3. **Code Analysis**: Deep code exploration with file reading and pattern matching. Best for understanding implementations.

## Content Types Available
- "issue": GitLab issues with titles, descriptions, labels
- "merge_request": MRs with titles, descriptions, diffs
- "code": Code snippets from repository files
- "comment": Comments/notes on issues and MRs

## Your Task
Analyze the query and return a JSON search plan with:

1. **intent**: One of:
   - "find_specific_item": Looking for a specific issue/MR by number
   - "search_by_criteria": Searching with filters (labels, state, date)
   - "code_exploration": Understanding code/implementation
   - "compare_items": Comparing multiple issues/MRs
   - "summarize": Overview or summary request
   - "troubleshoot": Debugging or finding why something doesn't work
   - "follow_up": References previous messages (it, that, the same)
   - "general_question": General project questions

2. **strategy**: One of:
   - "api_only": Only fetch from GitLab API (specific IIDs, real-time data)
   - "vector_only": Only semantic search (conceptual questions)
   - "api_first": API then augment with vector search
   - "vector_first": Vector search then API for specifics
   - "parallel": Run both and merge results
   - "code_deep": Use code analysis agent for deep exploration

3. **sub_queries**: List of queries to execute:
   - For API queries: {{"query_type": "api", "action": "get_issue|get_mr|search_issues|search_mrs", "params": {{...}}}}
   - For vector queries: {{"query_type": "vector", "query": "search text", "content_types": ["issue", "code", ...]}}
   - For code analysis: {{"query_type": "code_analysis", "query": "what to analyze"}}

4. **content_priority**: Ordered list of content types to prioritize in results

5. **requires_code_analysis**: Boolean - whether to engage deep code analysis

6. **resolved_references**: If the query references previous context ("it", "that issue", "the same MR"), resolve them here

7. **reasoning**: Brief explanation of why this plan was chosen

## Conversation History
{conversation_history}

## Current Query
{query}

## Return Format
Return ONLY a valid JSON object with the search plan. No markdown, no explanation outside JSON.
"""

    def __init__(self):
        settings = get_settings()
        base_url = settings.openai_base_url if settings.openai_base_url else None
        self.openai = OpenAI(api_key=settings.openai_api_key, base_url=base_url)
        self.model = settings.openai_model

    def _format_conversation_history(
        self, history: List[Dict[str, str]], max_messages: int = 6
    ) -> str:
        """Format conversation history for the prompt."""
        if not history:
            return "No previous conversation."

        formatted = []
        for msg in history[-max_messages:]:
            role = msg.get("role", "user").capitalize()
            content = msg.get("content", "")[:500]  # Truncate long messages
            formatted.append(f"{role}: {content}")

        return "\n".join(formatted)

    async def plan(
        self,
        query: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
    ) -> SearchPlan:
        """Generate a search plan for the given query.

        Args:
            query: The user's query
            conversation_history: Previous messages in the conversation

        Returns:
            SearchPlan with strategy and sub-queries
        """
        conversation_history = conversation_history or []

        try:
            history_text = self._format_conversation_history(conversation_history)

            response = self.openai.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": self.PLANNING_PROMPT.format(
                            conversation_history=history_text,
                            query=query,
                        ),
                    }
                ],
                temperature=0,
                max_tokens=1000,
            )

            content = response.choices[0].message.content.strip()

            # Extract JSON from response
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            plan_data = json.loads(content)
            return self._parse_plan(query, plan_data)

        except (json.JSONDecodeError, Exception) as e:
            logger.warning(f"Query planning failed: {e}, using default plan")
            return self._create_default_plan(query)

    def _parse_plan(self, query: str, data: Dict[str, Any]) -> SearchPlan:
        """Parse JSON response into SearchPlan."""
        # Parse intent
        intent_str = data.get("intent", "general_question")
        try:
            intent = SearchIntent(intent_str)
        except ValueError:
            intent = SearchIntent.GENERAL_QUESTION

        # Parse strategy
        strategy_str = data.get("strategy", "parallel")
        try:
            strategy = SearchStrategy(strategy_str)
        except ValueError:
            strategy = SearchStrategy.PARALLEL

        # Parse sub-queries
        sub_queries = []
        for sq_data in data.get("sub_queries", []):
            sub_query = SubQuery(
                query_type=sq_data.get("query_type", "vector"),
                query=sq_data.get("query", query),
                action=sq_data.get("action"),
                params=sq_data.get("params", {}),
                content_types=sq_data.get("content_types"),
                priority=sq_data.get("priority", 1),
            )
            sub_queries.append(sub_query)

        # Ensure at least one sub-query
        if not sub_queries:
            sub_queries.append(
                SubQuery(query_type="vector", query=query, priority=1)
            )

        return SearchPlan(
            original_query=query,
            intent=intent,
            strategy=strategy,
            reasoning=data.get("reasoning", "Default plan"),
            sub_queries=sub_queries,
            content_priority=data.get("content_priority", ["issue", "merge_request", "code", "comment"]),
            requires_code_analysis=data.get("requires_code_analysis", False),
            resolved_references=data.get("resolved_references", {}),
            confidence=data.get("confidence", 0.8),
        )

    def _create_default_plan(self, query: str) -> SearchPlan:
        """Create a default search plan when planning fails."""
        # Simple heuristics for fallback
        query_lower = query.lower()

        # Check for specific item references
        import re

        issue_match = re.search(r"#(\d+)", query)
        mr_match = re.search(r"!(\d+)", query)

        sub_queries = []

        if issue_match:
            sub_queries.append(
                SubQuery(
                    query_type="api",
                    query=query,
                    action="get_issue",
                    params={"issue_iid": int(issue_match.group(1))},
                    priority=1,
                )
            )

        if mr_match:
            sub_queries.append(
                SubQuery(
                    query_type="api",
                    query=query,
                    action="get_mr",
                    params={"mr_iid": int(mr_match.group(1))},
                    priority=1,
                )
            )

        # Always include vector search
        sub_queries.append(
            SubQuery(query_type="vector", query=query, priority=2)
        )

        # Determine if code analysis needed
        code_keywords = ["code", "function", "class", "implementation", "file", "method"]
        requires_code = any(kw in query_lower for kw in code_keywords)

        if requires_code:
            sub_queries.append(
                SubQuery(query_type="code_analysis", query=query, priority=3)
            )

        return SearchPlan(
            original_query=query,
            intent=SearchIntent.GENERAL_QUESTION,
            strategy=SearchStrategy.PARALLEL,
            reasoning="Fallback plan due to planning failure",
            sub_queries=sub_queries,
            content_priority=["issue", "merge_request", "code", "comment"],
            requires_code_analysis=requires_code,
            confidence=0.5,
        )
